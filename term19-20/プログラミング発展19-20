{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurihara-ryo/cesarean-pasaran/blob/main/%E3%80%90%E8%A7%A3%E7%AD%94%E4%BE%8B%E3%80%91%E7%99%BA%E5%B1%95%E8%AA%B2%E9%A1%8C_%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E2%85%A2_1920.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 各課題について、コメントを参考にしてプログラムを書いてください。\n",
        "# 実行ボタンを押して、プログラムが正しく実行されることを確認してください。\n",
        "# 提出の際は、コメントを削除せずに残してください。\n",
        "# 全ての課題を解けなかった場合でも、〆切までに提出すれば途中点が付与されます。"
      ],
      "metadata": {
        "id": "iXcVPPdWXAzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "課題1\n",
        "\n",
        "Fashion MNISTデータセットに対して、講義資料に記載の「発展課題の指定の多層パーセプトロン」を作成して、各エポックの損失関数の値を表示してください。学習後のモデルを使って、テストデータに対するaccuracyを計算して表示してください。学習のエポック数は20とします。それ以外の設定は演習課題と同じにしてください。"
      ],
      "metadata": {
        "id": "dzLyFVlfJva1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 問題文のコード: このセルは変更しない\n",
        "\n",
        "# 必要なモジュール一式を準備\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 乱数シードの設定\n",
        "seed = 42 # 変更しない\n",
        "torch.manual_seed(seed)\n",
        "print('Random seed: {}'.format(seed))\n",
        "\n",
        "# データセットの読み込み\n",
        "transform = transforms.ToTensor()\n",
        "train_val_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 学習データとバリデーションデータに分割\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [50000, 10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbZqVziij4n",
        "outputId": "5551c742-90ec-4cf9-f2dd-a43dc573acbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.8MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 273kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.87MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 7.41MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 解答欄: このセルにコードを書く\n",
        "\n",
        "# 乱数シードの設定\n",
        "torch.manual_seed(seed)\n",
        "print('Random seed: {}'.format(seed))\n",
        "\n",
        "# GPUを使えるか判定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: {}'.format(device))\n",
        "\n",
        "# accuracy計算用の関数\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            outputs = model(X)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_true_list.extend(y.numpy())\n",
        "            y_pred_list.extend(preds.cpu().numpy())\n",
        "    acc = accuracy_score(y_true_list, y_pred_list)\n",
        "    return acc\n",
        "\n",
        "# ネットワーク構造の定義\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 256),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.BatchNorm1d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.BatchNorm1d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ").to(device)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# SGDの定義\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# dataloaderの作成\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 学習ループ\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * X_batch.size(0)\n",
        "    # 学習データに対する損失\n",
        "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
        "    # バリデーションデータに対する損失\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in val_loader:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "            outputs = model(X_val)\n",
        "            loss = criterion(outputs, y_val)\n",
        "            val_loss += loss.item() * X_val.size(0)\n",
        "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "    # 学習データ、バリデーションデータに対する損失を表示\n",
        "    print('Epoch {}, Train Loss: {}, Val Loss: {}'.format(epoch, avg_loss, avg_val_loss))\n",
        "\n",
        "\n",
        "# テストデータに対するaccuracy\n",
        "test_acc = evaluate(model, test_loader)\n",
        "print('Accuracy on test data: {}'.format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCTqwZ3HHD8b",
        "outputId": "8b85ec30-f06a-4607-94ac-a1446f5f8efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed: 42\n",
            "Using device: cpu\n",
            "Epoch 0, Train Loss: 0.5842262268161774, Val Loss: 0.4113363204956055\n",
            "Epoch 1, Train Loss: 0.40654631521224976, Val Loss: 0.35773919796943665\n",
            "Epoch 2, Train Loss: 0.37024075863838196, Val Loss: 0.32775277841091155\n",
            "Epoch 3, Train Loss: 0.34119327242851255, Val Loss: 0.3549328071832657\n",
            "Epoch 4, Train Loss: 0.3229712278652191, Val Loss: 0.33235118548870085\n",
            "Epoch 5, Train Loss: 0.30661584862709046, Val Loss: 0.32526862568855286\n",
            "Epoch 6, Train Loss: 0.2908597865867615, Val Loss: 0.3135196929693222\n",
            "Epoch 7, Train Loss: 0.2795421890735626, Val Loss: 0.3147251296877861\n",
            "Epoch 8, Train Loss: 0.2684664634716511, Val Loss: 0.31132470020651815\n",
            "Epoch 9, Train Loss: 0.25738847270965576, Val Loss: 0.324885373878479\n",
            "Epoch 10, Train Loss: 0.2499950434923172, Val Loss: 0.3319114218354225\n",
            "Epoch 11, Train Loss: 0.24035320125102996, Val Loss: 0.3042961975216866\n",
            "Epoch 12, Train Loss: 0.2289190240550041, Val Loss: 0.30712109518647196\n",
            "Epoch 13, Train Loss: 0.22476085129737855, Val Loss: 0.3084026373445988\n",
            "Epoch 14, Train Loss: 0.2188731961965561, Val Loss: 0.3477046983718872\n",
            "Epoch 15, Train Loss: 0.20434912260532379, Val Loss: 0.3279886617124081\n",
            "Epoch 16, Train Loss: 0.20114146272182465, Val Loss: 0.3164373963832855\n",
            "Epoch 17, Train Loss: 0.19577301203250885, Val Loss: 0.304713426554203\n",
            "Epoch 18, Train Loss: 0.1882201656627655, Val Loss: 0.32023006410598753\n",
            "Epoch 19, Train Loss: 0.18372497286319733, Val Loss: 0.32800889785289766\n",
            "Accuracy on test data: 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "課題2\n",
        "\n",
        "Fashion MNISTデータセットに対して、講義資料に記載の「発展課題の指定のCNN」を作成して、各エポックの損失関数の値を表示してください。学習後のモデルを使って、テストデータに対するaccuracyを計算して表示してください。\n",
        "\n",
        "*   畳み込み層のカーネルサイズは3、ストライドは1とし、パディングはshapeが合うように適切に設定する\n",
        "\n",
        "*   最大プーリング層のカーネルサイズは2、ストライドは2、他はデフォルト値に設定する\n",
        "*   ドロップアウト、バッチ正規化は使用しない\n",
        "*   学習のエポック数は20とする\n",
        "*   それ以外の設定は演習課題と同じにする\n"
      ],
      "metadata": {
        "id": "GF1pNCLHJp8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 問題文のコード: このセルは変更しない\n",
        "\n",
        "# 必要なモジュール一式を準備\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 乱数シードの設定\n",
        "seed = 42 # 変更しない\n",
        "torch.manual_seed(seed)\n",
        "print('Random seed: {}'.format(seed))\n",
        "\n",
        "# データセットの読み込み\n",
        "transform = transforms.ToTensor()\n",
        "train_val_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 学習データとバリデーションデータに分割\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [50000, 10000])"
      ],
      "metadata": {
        "id": "Fyf6bZcOJnez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### 解答欄: このセルにコードを書く\n",
        "\n",
        "# 乱数シードの設定\n",
        "torch.manual_seed(seed)\n",
        "print('Random seed: {}'.format(seed))\n",
        "\n",
        "# GPUを使えるか判定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: {}'.format(device))\n",
        "\n",
        "# accuracy計算用の関数\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    y_true_list = []\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            outputs = model(X)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_true_list.extend(y.numpy())\n",
        "            y_pred_list.extend(preds.cpu().numpy())\n",
        "    acc = accuracy_score(y_true_list, y_pred_list)\n",
        "    return acc\n",
        "\n",
        "# ネットワーク構造の定義\n",
        "model = nn.Sequential(\n",
        "    # 畳み込み＆プーリング1\n",
        "    nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    # 畳み込み＆プーリング2\n",
        "    nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    # 畳み込み＆プーリング3\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=2),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    # 全結合層\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 4 * 4, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# SGDの定義\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# dataloaderの作成\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 学習ループ\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * X_batch.size(0)\n",
        "    # 学習データに対する損失\n",
        "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
        "    # バリデーションデータに対する損失\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in val_loader:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "            outputs = model(X_val)\n",
        "            loss = criterion(outputs, y_val)\n",
        "            val_loss += loss.item() * X_val.size(0)\n",
        "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "    # 学習データ、バリデーションデータに対する損失を表示\n",
        "    print('Epoch {}, Train Loss: {}, Val Loss: {}'.format(epoch, avg_loss, avg_val_loss))\n",
        "\n",
        "\n",
        "# テストデータに対するaccuracy\n",
        "test_acc = evaluate(model, test_loader)\n",
        "print('Accuracy on test data: {}'.format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HKqzSrzi0xf",
        "outputId": "9c598ab7-c716-4b61-db22-f1367bef12d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed: 42\n",
            "Using device: cpu\n",
            "Epoch 0, Train Loss: 0.7052591214370727, Val Loss: 0.4846860621929169\n",
            "Epoch 1, Train Loss: 0.43716235905647277, Val Loss: 0.40596585574150085\n",
            "Epoch 2, Train Loss: 0.36887413932800295, Val Loss: 0.3419895356893539\n",
            "Epoch 3, Train Loss: 0.33131251508712767, Val Loss: 0.32902903664112093\n",
            "Epoch 4, Train Loss: 0.30505477964401245, Val Loss: 0.2984756233215332\n",
            "Epoch 5, Train Loss: 0.2876919265127182, Val Loss: 0.34032190563678744\n",
            "Epoch 6, Train Loss: 0.27303230127334593, Val Loss: 0.274623347568512\n",
            "Epoch 7, Train Loss: 0.2579004875469208, Val Loss: 0.26922418149709704\n",
            "Epoch 8, Train Loss: 0.24597004652023316, Val Loss: 0.2626716869056225\n",
            "Epoch 9, Train Loss: 0.23485792303562164, Val Loss: 0.28078388061523435\n",
            "Epoch 10, Train Loss: 0.2254681892633438, Val Loss: 0.2887660243034363\n",
            "Epoch 11, Train Loss: 0.21426686821460725, Val Loss: 0.2583668856024742\n",
            "Epoch 12, Train Loss: 0.20763631850242614, Val Loss: 0.255142587223649\n",
            "Epoch 13, Train Loss: 0.1977257214742899, Val Loss: 0.2494452620983124\n",
            "Epoch 14, Train Loss: 0.19189011674404144, Val Loss: 0.25439973362088203\n",
            "Epoch 15, Train Loss: 0.18110259093761444, Val Loss: 0.2501148381203413\n",
            "Epoch 16, Train Loss: 0.1753292069196701, Val Loss: 0.24417472762167453\n",
            "Epoch 17, Train Loss: 0.16983259718894958, Val Loss: 0.24622416228950023\n",
            "Epoch 18, Train Loss: 0.1617177509880066, Val Loss: 0.24917043385580182\n",
            "Epoch 19, Train Loss: 0.15507364720106126, Val Loss: 0.25302523729503157\n",
            "Accuracy on test data: 0.9097\n"
          ]
        }
      ]
    }
  ]
}
