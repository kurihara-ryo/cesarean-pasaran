{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurihara-ryo/cesarean-pasaran/blob/main/%E3%80%90%E8%A7%A3%E7%AD%94%E4%BE%8B%E3%80%91%E3%83%AC%E3%83%9B%E3%82%9A%E3%83%BC%E3%83%88%E8%AA%B2%E9%A1%8C_%E3%83%95%E3%82%9A%E3%83%AD%E3%82%AF%E3%82%99%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%AF%E3%82%99%E2%85%A2_1112.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "各課題について、コメントを参考にしてプログラムを書いてください。実行ボタンを押して、プログラムが正しく実行されることを確認してください。提出の際は、コメントを削除せずに残してください。全ての課題を解けなかった場合でも、〆切までに提出すれば途中点が付与されます。**レポート課題は配点が大きいので、必ず期限内に提出してください。未提出の場合、<font color='red'>単位を落とす可能性が非常に高くなります</font>。**"
      ],
      "metadata": {
        "id": "2xRJvpRNKT9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題1\n",
        "\n",
        "2クラス分類のためのニューラルネットワークをPythonで1から書いてみましょう。交差エントロピー誤差を損失関数として、確率的勾配降下法を用いて学習を行ってください。学習したモデルの予測精度を評価してください。以下の手順に沿って進めてください。"
      ],
      "metadata": {
        "id": "j0MXM7c3Ar0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順1\n",
        "\n",
        "csvファイルから学習データをデータフレームとして読み込み、内容を確認してください。また、データフレームを入力と予測対象に分けて、それぞれをnumpyアレイに格納してください。"
      ],
      "metadata": {
        "id": "0dNIyIMhQ08h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モジュールの準備\n",
        "# numpy, pandas, gdownをimportする。\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "# 学習データのcsvファイルをダウンロード\n",
        "url='https://drive.google.com/uc?export=download&id=17RctbyvrxeSI2gnriFf3tGuWWvPxzol8'\n",
        "gdown.download(url, 'kadai1_data_train.csv', quiet=False)\n",
        "\n",
        "# csvファイルをデータフレームとして読み込む\n",
        "df = pd.read_csv('kadai1_data_train.csv')\n",
        "\n",
        "# データフレームを画面に表示\n",
        "# 各行が1個の学習データを表している。\n",
        "# 入力xは2次元ベクトルx1, x2として記載されている。\n",
        "# 各xについて予測対象yの真の値が記載されている。\n",
        "# 2クラス分類なのでyは0, 1どちらか。\n",
        "# 学習データ数は50個。\n",
        "display(df)\n",
        "\n",
        "# データフレームをXとy_trueに分ける\n",
        "# Xは50個の2次元ベクトルが並んだ50行2列のデータフレーム。\n",
        "# y_trueは50個の値が並んだ50行1列のデータフレーム。\n",
        "X = df.iloc[:, :-1]\n",
        "y_true = df.iloc[:, -1]\n",
        "\n",
        "# 今後の計算を行いやすくするため、X, y_trueをnumpyアレイに変換しておく。\n",
        "# to_numpy()を使うとデータフレームをnumpyアレイに変換できる。\n",
        "X = X.to_numpy()\n",
        "y_true = y_true.to_numpy()\n",
        "\n",
        "# Xとy_trueをprint()で確認\n",
        "# Xは50行2列の行列、y_trueは長さ50のベクトルになっているはず。\n",
        "print('X:\\n{}\\n'.format(X))\n",
        "print('y_true:\\n{}'.format(y_true))\n",
        "\n",
        "# 注意:\n",
        "# 今回のデータセットは課題用に適切な前処理を行ってあるため、\n",
        "# 自分でStandardScalerなどの前処理を行う必要はありません。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W9jGZUxKFKBm",
        "outputId": "2c3c7339-b434-40f1-a43a-cdc120180e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=17RctbyvrxeSI2gnriFf3tGuWWvPxzol8\n",
            "To: /content/kadai1_data_train.csv\n",
            "100%|██████████| 2.09k/2.09k [00:00<00:00, 4.15MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          x1        x2  y\n",
              "0   0.867181  1.019686  0\n",
              "1   0.147789  0.948173  1\n",
              "2   0.960789  0.853649  0\n",
              "3  -0.054438  0.011092  0\n",
              "4   1.091540  1.032875  0\n",
              "5  -0.046342  0.953427  1\n",
              "6   0.082254  0.877916  1\n",
              "7   0.858463 -0.042065  1\n",
              "8   1.157921  1.076743  0\n",
              "9   0.081253  0.135624  0\n",
              "10 -0.115099  1.037570  1\n",
              "11 -0.101283  0.031425  0\n",
              "12  0.932308  0.061168  1\n",
              "13  1.024196 -0.191328  1\n",
              "14  1.036164 -0.064512  1\n",
              "15 -0.046947  0.054256  0\n",
              "16 -0.261975  1.082190  1\n",
              "17  0.034362 -0.176304  0\n",
              "18 -0.052976  0.051327  0\n",
              "19 -0.007201  1.100353  1\n",
              "20  0.000511  0.976541  1\n",
              "21  0.939829  1.185228  0\n",
              "22 -0.090802  0.858770  1\n",
              "23 -0.001350 -0.105771  0\n",
              "24  0.952083 -0.018566  1\n",
              "25 -0.003583  0.156464  0\n",
              "26  0.032408  0.961492  1\n",
              "27  1.006753  0.857525  0\n",
              "28  0.049671 -0.013826  0\n",
              "29  0.929795 -0.032766  1\n",
              "30  1.103100  1.093128  0\n",
              "31  0.889367  0.880379  0\n",
              "32  1.009176  0.801243  0\n",
              "33  0.033126  1.097555  1\n",
              "34  0.009708  1.096864  1\n",
              "35  0.064769  1.152303  1\n",
              "36 -0.011565  0.969890  1\n",
              "37  0.976585 -0.023414  1\n",
              "38 -0.021967  0.035711  0\n",
              "39  1.036140  1.153804  0\n",
              "40  0.953936  1.105712  0\n",
              "41  0.029612  0.026106  0\n",
              "42  1.146565 -0.022578  1\n",
              "43  0.852148 -0.071984  1\n",
              "44  1.020886 -0.195967  1\n",
              "45  0.965729  0.919772  0\n",
              "46  0.073847  0.017137  0\n",
              "47  0.827508  0.943771  0\n",
              "48  0.919151 -0.050176  1\n",
              "49  0.939936 -0.029169  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f634455-996b-457e-a15e-36888c70b026\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.867181</td>\n",
              "      <td>1.019686</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.147789</td>\n",
              "      <td>0.948173</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.960789</td>\n",
              "      <td>0.853649</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.054438</td>\n",
              "      <td>0.011092</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.091540</td>\n",
              "      <td>1.032875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.046342</td>\n",
              "      <td>0.953427</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.082254</td>\n",
              "      <td>0.877916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.858463</td>\n",
              "      <td>-0.042065</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.157921</td>\n",
              "      <td>1.076743</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.081253</td>\n",
              "      <td>0.135624</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.115099</td>\n",
              "      <td>1.037570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.101283</td>\n",
              "      <td>0.031425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.932308</td>\n",
              "      <td>0.061168</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.024196</td>\n",
              "      <td>-0.191328</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.036164</td>\n",
              "      <td>-0.064512</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.046947</td>\n",
              "      <td>0.054256</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.261975</td>\n",
              "      <td>1.082190</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.034362</td>\n",
              "      <td>-0.176304</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.052976</td>\n",
              "      <td>0.051327</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.007201</td>\n",
              "      <td>1.100353</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.976541</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.939829</td>\n",
              "      <td>1.185228</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.090802</td>\n",
              "      <td>0.858770</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.001350</td>\n",
              "      <td>-0.105771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.952083</td>\n",
              "      <td>-0.018566</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-0.003583</td>\n",
              "      <td>0.156464</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.032408</td>\n",
              "      <td>0.961492</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.006753</td>\n",
              "      <td>0.857525</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.049671</td>\n",
              "      <td>-0.013826</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.929795</td>\n",
              "      <td>-0.032766</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.103100</td>\n",
              "      <td>1.093128</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.889367</td>\n",
              "      <td>0.880379</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1.009176</td>\n",
              "      <td>0.801243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.033126</td>\n",
              "      <td>1.097555</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.009708</td>\n",
              "      <td>1.096864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.064769</td>\n",
              "      <td>1.152303</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-0.011565</td>\n",
              "      <td>0.969890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.976585</td>\n",
              "      <td>-0.023414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>-0.021967</td>\n",
              "      <td>0.035711</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1.036140</td>\n",
              "      <td>1.153804</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.953936</td>\n",
              "      <td>1.105712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.029612</td>\n",
              "      <td>0.026106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1.146565</td>\n",
              "      <td>-0.022578</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.852148</td>\n",
              "      <td>-0.071984</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1.020886</td>\n",
              "      <td>-0.195967</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.965729</td>\n",
              "      <td>0.919772</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.073847</td>\n",
              "      <td>0.017137</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.827508</td>\n",
              "      <td>0.943771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.919151</td>\n",
              "      <td>-0.050176</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.939936</td>\n",
              "      <td>-0.029169</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f634455-996b-457e-a15e-36888c70b026')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f634455-996b-457e-a15e-36888c70b026 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f634455-996b-457e-a15e-36888c70b026');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af3115b5-2f00-4d75-8e6b-e30504d2b04c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af3115b5-2f00-4d75-8e6b-e30504d2b04c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af3115b5-2f00-4d75-8e6b-e30504d2b04c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4c8b4002-3bc1-48d0-86b6-7360b1d2298e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4c8b4002-3bc1-48d0-86b6-7360b1d2298e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5035752973298507,\n        \"min\": -0.2619745104089744,\n        \"max\": 1.1579212815507391,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          1.0241962271566034,\n          1.0361395605508414,\n          1.103099952249595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5243314040478623,\n        \"min\": -0.1959670123879775,\n        \"max\": 1.1852278184508938,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          -0.1913280244657798,\n          1.153803656646597,\n          1.0931280119116198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            "[[ 8.67181395e-01  1.01968612e+00]\n",
            " [ 1.47789404e-01  9.48172978e-01]\n",
            " [ 9.60789185e-01  8.53648505e-01]\n",
            " [-5.44382725e-02  1.10922590e-02]\n",
            " [ 1.09154021e+00  1.03287511e+00]\n",
            " [-4.63417693e-02  9.53427025e-01]\n",
            " [ 8.22544912e-02  8.77915635e-01]\n",
            " [ 8.58462926e-01 -4.20645323e-02]\n",
            " [ 1.15792128e+00  1.07674347e+00]\n",
            " [ 8.12525822e-02  1.35624003e-01]\n",
            " [-1.15099358e-01  1.03756980e+00]\n",
            " [-1.01283112e-01  3.14247333e-02]\n",
            " [ 9.32307800e-01  6.11676289e-02]\n",
            " [ 1.02419623e+00 -1.91328024e-01]\n",
            " [ 1.03616360e+00 -6.45119755e-02]\n",
            " [-4.69474386e-02  5.42560044e-02]\n",
            " [-2.61974510e-01  1.08219025e+00]\n",
            " [ 3.43618290e-02 -1.76304016e-01]\n",
            " [-5.29760204e-02  5.13267433e-02]\n",
            " [-7.20101216e-03  1.10035329e+00]\n",
            " [ 5.11345664e-04  9.76541287e-01]\n",
            " [ 9.39829339e-01  1.18522782e+00]\n",
            " [-9.08024076e-02  8.58769630e-01]\n",
            " [-1.34972247e-03 -1.05771093e-01]\n",
            " [ 9.52082576e-01 -1.85658977e-02]\n",
            " [-3.58260391e-03  1.56464366e-01]\n",
            " [ 3.24083969e-02  9.61491772e-01]\n",
            " [ 1.00675282e+00  8.57525181e-01]\n",
            " [ 4.96714153e-02 -1.38264301e-02]\n",
            " [ 9.29794691e-01 -3.27662147e-02]\n",
            " [ 1.10309995e+00  1.09312801e+00]\n",
            " [ 8.89366503e-01  8.80379338e-01]\n",
            " [ 1.00917608e+00  8.01243109e-01]\n",
            " [ 3.31263431e-02  1.09755451e+00]\n",
            " [ 9.70775493e-03  1.09686450e+00]\n",
            " [ 6.47688538e-02  1.15230299e+00]\n",
            " [-1.15648282e-02  9.69889630e-01]\n",
            " [ 9.76584663e-01 -2.34136957e-02]\n",
            " [-2.19671888e-02  3.57112572e-02]\n",
            " [ 1.03613956e+00  1.15380366e+00]\n",
            " [ 9.53936123e-01  1.10571222e+00]\n",
            " [ 2.96120277e-02  2.61055272e-02]\n",
            " [ 1.14656488e+00 -2.25776300e-02]\n",
            " [ 8.52147801e-01 -7.19844208e-02]\n",
            " [ 1.02088636e+00 -1.95967012e-01]\n",
            " [ 9.65728548e-01  9.19772273e-01]\n",
            " [ 7.38466580e-02  1.71368281e-02]\n",
            " [ 8.27508217e-01  9.43771247e-01]\n",
            " [ 9.19150640e-01 -5.01757044e-02]\n",
            " [ 9.39936131e-01 -2.91693750e-02]]\n",
            "\n",
            "y_true:\n",
            "[0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 1 0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順2\n",
        "\n",
        "以下のセルを読み、本課題におけるニューラルネットワークの表現方法について確認してください。また、活性化関数、出力関数、順方向計算の関数、損失関数を書いてください。"
      ],
      "metadata": {
        "id": "YC2DG7wWK81g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 本課題では、ニューラルネットワーク内の変数を辞書varsを用いて表現する。\n",
        "# 辞書のキーは各変数がどの層の変数なのかを文字列で表し、\n",
        "# 辞書の値は各変数の現在の値をリストやスカラーとして格納する。\n",
        "# 変数の値は学習の過程で変化していく。\n",
        "# 今は適当に0.0を入れてある。\n",
        "vars = {\n",
        "    'x': [0.0, 0.0], # 入力層の変数のリスト(x1, x2)\n",
        "    'u1': [0.0, 0.0], # 1層目の変数のリスト(活性化関数に入れる前)\n",
        "    'z1': [0.0, 0.0], # 1層目の変数のリスト(活性化関数の計算結果)\n",
        "    'u2': [0.0, 0.0], # 2層目の変数のリスト(活性化関数に入れる前)\n",
        "    'z2': [0.0, 0.0], # 2層目の変数のリスト(活性化関数の計算結果)\n",
        "    'u3': 0.0, # 出力層の変数(出力関数に入れる前)\n",
        "    'y_pred': 0.0 # 出力関数の計算結果、つまりyの予測値\n",
        "}\n",
        "\n",
        "# ニューラルネットワークのパラメータを辞書paramsを用いて表現する。\n",
        "# 辞書のキーは各パラメータがどの層のパラメータなのかを文字列として表し、\n",
        "# 辞書の値は各パラメータの現在の値をリストやスカラーとして格納する。\n",
        "# 例えば、W1はユニットiからユニットjへの重みをW1[j][i]で表す。\n",
        "# b1はユニットjへのバイアスをb1[j]で表す。\n",
        "# W2, b2も同様。\n",
        "# W3, b3は出力層のユニット数が1なので次元が減る。\n",
        "# パラメータの値は学習の過程で変化していく。\n",
        "# 今は適当に0.0を入れてある。\n",
        "params = {\n",
        "    'W1': [[0.0, 0.0], [0.0, 0.0]], # 入力層から1層目への重みパラメータ\n",
        "    'b1': [0.0, 0.0], # 入力層から1層目へのバイアスパラメータ\n",
        "    'W2': [[0.0, 0.0], [0.0, 0.0]], # 1層目から2層目への重みパラメータ\n",
        "    'b2': [0.0, 0.0], # 1層目から2層目へのバイアスパラメータ\n",
        "    'W3': [0.0, 0.0], # 2層目から出力層への重みパラメータ\n",
        "    'b3': 0.0 # 2層目から出力層へのバイアスパラメータ\n",
        "}\n",
        "\n",
        "\n",
        "# 活性化関数および出力関数にはシグモイド関数を用いる。\n",
        "# 引数はスカラー、戻り値はスカラー。\n",
        "def sigmoid(u):\n",
        "    return 1 / (1 + np.exp(-u))\n",
        "\n",
        "\n",
        "# 順方向計算の関数\n",
        "# 入力変数のリストxとパラメータの辞書paramsを引数として受け取り、\n",
        "# 変数の辞書varsを戻り値として返す。\n",
        "def forward_prop(x, params):\n",
        "    # 入力層から1層目への計算\n",
        "    u1 = [0.0, 0.0] # 初期化\n",
        "    z1 = [0.0, 0.0] # 初期化\n",
        "    for j in range(2):\n",
        "        u1[j] = x[0] * params['W1'][j][0] + x[1] * params['W1'][j][1] + params['b1'][j]\n",
        "        z1[j] = sigmoid(u1[j])\n",
        "\n",
        "    # 1層目から2層目への計算\n",
        "    u2 = [0.0, 0.0]\n",
        "    z2 = [0.0, 0.0]\n",
        "    for j in range(2):\n",
        "        u2[j] = z1[0] * params['W2'][j][0] + z1[1] * params['W2'][j][1] + params['b2'][j]\n",
        "        z2[j] = sigmoid(u2[j])\n",
        "\n",
        "    # 2層目から出力層への計算\n",
        "    u3 = z2[0] * params['W3'][0] + z2[1] * params['W3'][1] + params['b3']\n",
        "    y_pred = sigmoid(u3)\n",
        "\n",
        "    vars = {'x': x, 'u1': u1, 'z1': z1, 'u2': u2, 'z2': z2, 'u3': u3, 'y_pred': y_pred}\n",
        "    return vars\n",
        "\n",
        "\n",
        "# 損失関数\n",
        "# 2クラス分類なので交差エントロピー誤差を用いる。\n",
        "# 引数y_true, y_predはベクトル、戻り値はスカラー。\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "\n",
        "# デバッグ用\n",
        "# 入力x = [0.0, 0.0]に対して順方向計算を行う。\n",
        "# エラーが出なくなるまで修正しよう。\n",
        "print('Example calculation for x = [0.0, 0.0]')\n",
        "vars = forward_prop([0.0, 0.0], params)\n",
        "# 変数の値の確認。\n",
        "# inf, nanなど異常値になっていないか確認しよう。\n",
        "print('Variables: {}'.format(vars))\n",
        "# u3, y_predの値を取得。\n",
        "# 今はパラメータを全て0.0に設定しているので、u3は0.0、y_predはsigmoid(0.0)=0.5になるはず。\n",
        "# 正しい答えが出るまで修正しよう。\n",
        "print('u3: {}'.format(vars['u3']))\n",
        "print('y_pred: {}'.format(vars['y_pred']))"
      ],
      "metadata": {
        "id": "g4v1icEMY30x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bd3d90-9167-4eff-9321-dd60083d961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example calculation for x = [0.0, 0.0]\n",
            "Variables: {'x': [0.0, 0.0], 'u1': [0.0, 0.0], 'z1': [np.float64(0.5), np.float64(0.5)], 'u2': [np.float64(0.0), np.float64(0.0)], 'z2': [np.float64(0.5), np.float64(0.5)], 'u3': np.float64(0.0), 'y_pred': np.float64(0.5)}\n",
            "u3: 0.0\n",
            "y_pred: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順3\n",
        "\n",
        "以下のセルを読み、本課題における勾配の表現方法について確認してください。また、活性化関数の導関数、誤差逆伝播の関数、パラメータ更新の関数を書いてください。"
      ],
      "metadata": {
        "id": "YYYiCDuoj5u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数の勾配を辞書gradsを用いて表現する。\n",
        "# パラメータの辞書paramsと同じ形式を用いて、\n",
        "# 各パラメータに関する損失関数の微分の値を格納する。\n",
        "# 微分の値は学習の過程で変化していく。\n",
        "# 今は適当に0.0を入れてある。\n",
        "grads = {\n",
        "    'dW1': [[0.0, 0.0], [0.0, 0.0]], # パラメータW1に関する微分\n",
        "    'db1': [0.0, 0.0], # パラメータb1に関する微分\n",
        "    'dW2': [[0.0, 0.0], [0.0, 0.0]], # パラメータW2に関する微分\n",
        "    'db2': [0.0, 0.0], # # パラメータb2に関する微分\n",
        "    'dW3': [0.0, 0.0], # パラメータW3に関する微分\n",
        "    'db3': 0.0 # パラメータb3に関する微分\n",
        "}\n",
        "\n",
        "\n",
        "# シグモイド関数の導関数\n",
        "# 誤差逆伝播に用いる。\n",
        "# 引数はスカラー、戻り値はスカラー。\n",
        "def sigmoid_deriv(u):\n",
        "    s = sigmoid(u)\n",
        "    return s * (1 - s)\n",
        "\n",
        "\n",
        "# 誤差逆伝播の関数\n",
        "# y_true、パラメータの辞書params、変数の辞書varsを引数として受け取り、\n",
        "# 勾配の辞書gradsを戻り値として返す。\n",
        "# y_trueは確率的勾配降下法の各ステップで選んだ1つの学習データにおける真のyの値。\n",
        "# ベクトルではなくスカラーなので注意。\n",
        "# 対応するyの予測値y_predはvarsに入っている。\n",
        "def backward_prop(y_true, params, vars):\n",
        "    x = vars['x']\n",
        "    u1, z1 = vars['u1'], vars['z1']\n",
        "    u2, z2 = vars['u2'], vars['z2']\n",
        "    u3, y_pred = vars['u3'], vars['y_pred']\n",
        "\n",
        "    # 出力層\n",
        "    dW3 = [0.0, 0.0] # 初期化\n",
        "    delta3 = y_pred - y_true # 出力層のデルタ、ニューラルネット用語の「誤差」\n",
        "    for j in range(2):\n",
        "        dW3[j] = delta3 * z2[j]\n",
        "    db3 = delta3\n",
        "\n",
        "    # 2層目\n",
        "    dW2 = [[0.0, 0.0], [0.0, 0.0]] # 初期化\n",
        "    delta2 = [0.0, 0.0] # 初期化\n",
        "    for j in range(2):\n",
        "        delta2[j] = delta3 * params['W3'][j] * sigmoid_deriv(u2[j])\n",
        "    for j in range(2):\n",
        "        for i in range(2):\n",
        "            dW2[j][i] = delta2[j] * z1[i]\n",
        "    db2 = delta2\n",
        "\n",
        "    # 1層目\n",
        "    dW1 = [[0.0, 0.0], [0.0, 0.0]] # 初期化\n",
        "    delta1 = [0.0, 0.0] # 初期化\n",
        "    for j in range(2):\n",
        "        for k in range(2):\n",
        "            delta1[j] += delta2[k] * params['W2'][k][j] * sigmoid_deriv(u1[j])\n",
        "    for j in range(2):\n",
        "        for i in range(2):\n",
        "            dW1[j][i] = delta1[j] * x[i]\n",
        "    db1 = delta1\n",
        "\n",
        "    grads = {'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2, 'W3': dW3, 'b3': db3}\n",
        "    return grads\n",
        "\n",
        "\n",
        "# パラメータ更新の関数\n",
        "# パラメータの辞書params、勾配の辞書grads、学習率lrを引数として受け取り、\n",
        "# 更新した辞書paramsを戻り値として返す。\n",
        "def update_params(params, grads, lr):\n",
        "    for j in range(2):\n",
        "        for i in range(2):\n",
        "            params['W1'][j][i] -= lr * grads['W1'][j][i]\n",
        "            params['W2'][j][i] -= lr * grads['W2'][j][i]\n",
        "        params['b1'][j] -= lr * grads['b1'][j]\n",
        "        params['b2'][j] -= lr * grads['b2'][j]\n",
        "    for j in range(2):\n",
        "        params['W3'][j] -= lr * grads['W3'][j]\n",
        "    params['b3'] -= lr * grads['b3']\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "# デバッグ用\n",
        "# まず入力x = [0.0, 0.0]に対して順方向計算を行い、\n",
        "print('Example calculation for x = [0.0, 0.0]')\n",
        "vars = forward_prop([0.0, 0.0], params)\n",
        "# y_true = 0として誤差逆伝播を行う。\n",
        "# エラーが出なくなるまで修正しよう。\n",
        "print('Back prop when y_true = 0')\n",
        "grads = backward_prop(0, params, vars)\n",
        "# 勾配の値の確認。\n",
        "# inf, nanなど異常値になっていないか確認しよう。\n",
        "print('Gradients: {}'.format(grads))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUyJ-mzujDI7",
        "outputId": "2d0173ba-63ed-4f47-f33b-37d97b5727e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example calculation for x = [0.0, 0.0]\n",
            "Back prop when y_true = 0\n",
            "Gradients: {'W1': [[np.float64(0.0), np.float64(0.0)], [np.float64(0.0), np.float64(0.0)]], 'b1': [np.float64(0.0), np.float64(0.0)], 'W2': [[np.float64(0.0), np.float64(0.0)], [np.float64(0.0), np.float64(0.0)]], 'b2': [np.float64(0.0), np.float64(0.0)], 'W3': [np.float64(0.25), np.float64(0.25)], 'b3': np.float64(0.5)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順4\n",
        "\n",
        "パラメータを初期化し、学習を行う前の損失関数の値と、学習データに対するROC AUCを計算してください。"
      ],
      "metadata": {
        "id": "1DBghqy9KOhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# パラメータの初期値\n",
        "# 通常、重みパラメータは乱数で初期化し、バイアスパラメータは0.0で初期化する。\n",
        "# 今回は採点の都合上、以下の固定値を用いる。(これも乱数で生成)\n",
        "params_init = {\n",
        "    'W1': [[-0.051964249505532176, -0.11119605035442469], [1.0417967990841295, -1.256739294064987]],\n",
        "    'b1': [0.0, 0.0],\n",
        "    'W2': [[0.7453876814972659, -1.7110537607276717], [-0.20586438172426652, -0.234571291207228]],\n",
        "    'b2': [0.0, 0.0],\n",
        "    'W3': [1.1281440438104338, -0.012625951627825618],\n",
        "    'b3': 0.0\n",
        "}\n",
        "\n",
        "# パラメータの初期化\n",
        "params = params_init\n",
        "\n",
        "# 初期パラメータでのyの予測値\n",
        "y_pred = np.zeros(y_true.shape[0])\n",
        "for i in range(y_true.shape[0]):\n",
        "    vars = forward_prop(X[i, :], params)\n",
        "    y_pred[i] = vars['y_pred']\n",
        "\n",
        "# 初期パラメータでの損失関数の値\n",
        "loss_init = cross_entropy_loss(y_true, y_pred)\n",
        "\n",
        "# 初期パラメータでのROC AUCの値\n",
        "auc_init = roc_auc_score(y_true=y_true, y_score=y_pred)\n",
        "\n",
        "print('Loss before training: {}'.format(loss_init))\n",
        "print('ROC AUC before training: {}'.format(auc_init))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYpetfdC1wOv",
        "outputId": "163acdbe-d57e-458a-d81c-53294a4a4fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss before training: 0.716568265403481\n",
            "ROC AUC before training: 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順5\n",
        "\n",
        "確率的勾配降下法による学習を行い、損失関数の値の変化を記録してください。"
      ],
      "metadata": {
        "id": "mzKrzsldLBJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# エポック数\n",
        "# 今回は1000に設定。\n",
        "n_epoch = 1000\n",
        "\n",
        "# 学習率\n",
        "# 今回は0.1に設定。\n",
        "learning_rate = 0.1\n",
        "\n",
        "# このリストに各エポック終了時の損失関数の値を記録していく\n",
        "loss_list = [loss_init] # まずは初期値を入れる\n",
        "\n",
        "# 確率的勾配降下法\n",
        "params = params_init\n",
        "for ep in range(n_epoch):\n",
        "    # バッチサイズ1なので普通にforを回せばいい\n",
        "    for i in range(y_true.shape[0]):\n",
        "        # i番目の学習データに対する順方向計算\n",
        "        vars = forward_prop(X[i, :], params)\n",
        "        # 誤差逆伝播\n",
        "        grads = backward_prop(y_true[i], params, vars)\n",
        "        # パラメータ更新\n",
        "        params = update_params(params, grads, learning_rate)\n",
        "    # エポック終了、損失関数を計算\n",
        "    for i in range(y_true.shape[0]):\n",
        "        vars = forward_prop(X[i, :], params)\n",
        "        y_pred[i] = vars['y_pred']\n",
        "    # 損失関数の値を記録\n",
        "    loss_list.append(cross_entropy_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "# 学習後の損失関数の値\n",
        "print('Loss after training: {}'.format(loss_list[-1]))\n",
        "\n",
        "# 学習後のROC AUC\n",
        "print('ROC AUC after training: {}'.format(roc_auc_score(y_true=y_true, y_score=y_pred)))\n",
        "\n",
        "# デバッグ用\n",
        "# 変数、パラメータ、勾配の値はinf, nanなどの異常値になっていないか。\n",
        "# 次元数はあっているか。\n",
        "# 例えば、スカラーが入るべきところにリストが入っていたりしないか。\n",
        "print('Variables:\\n{}'.format(vars))\n",
        "print('Parameters:\\n{}'.format(params))\n",
        "print('Gradients:\\n{}'.format(grads))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ILztg_p5dW-",
        "outputId": "f8bb75f4-5cd0-4514-ab7b-445abe5c5ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after training: 0.002173218831617057\n",
            "ROC AUC after training: 1.0\n",
            "Variables:\n",
            "{'x': array([ 0.93993613, -0.02916937]), 'u1': [np.float64(-2.477762987125855), np.float64(8.001115928330243)], 'z1': [np.float64(0.07743185476747894), np.float64(0.9996650237622301)], 'u2': [np.float64(-7.90219231959701), np.float64(3.213095647016618)], 'z2': [np.float64(0.0003697948436111863), np.float64(0.9613241263635219)], 'u3': np.float64(6.188110822013353), 'y_pred': np.float64(0.9979505061503959)}\n",
            "Parameters:\n",
            "{'W1': [[np.float64(-4.839224870291986), np.float64(5.141003992400416)], [np.float64(5.909169738309202), np.float64(-5.449803639474477)]], 'b1': [np.float64(2.220759187759211), np.float64(2.2879064211100952)], 'W2': [[np.float64(2.5232506207874335), np.float64(-9.718108104848264)], [np.float64(-9.04891715663033), np.float64(2.5978622994041656)]], 'b2': [np.float64(1.6172804743492877), np.float64(1.3167780088268994)], 'W3': [np.float64(12.93121072807938), np.float64(13.00003869211803)], 'b3': np.float64(-6.313921911427888)}\n",
            "Gradients:\n",
            "{'W1': [[np.float64(0.0006007489651840585), np.float64(-1.8643258042546133e-05)], [np.float64(-7.806065651400502e-07), np.float64(2.4224843432152676e-08)]], 'b1': [np.float64(0.0006391380705194627), np.float64(-8.304889442890317e-07)], 'W2': [[np.float64(-7.590867935489142e-07), np.float64(-9.798915594892502e-06)], [np.float64(-7.677191055548053e-05), np.float64(-0.0009910348566001166)]], 'b2': [np.float64(-9.802199099182288e-06), np.float64(-0.0009913669410202201)], 'W3': [np.float64(-7.583068266455194e-07), np.float64(-0.001971245601493462)], 'b3': np.float64(-0.0020505744551551075)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順6\n",
        "\n",
        "手順5で計算した損失関数の値から学習曲線を描いてください。"
      ],
      "metadata": {
        "id": "Z9HQhTDZLF75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習曲線\n",
        "# x軸：確率的勾配降下法のエポック\n",
        "# y軸：そのエポックにおける損失関数の値\n",
        "plt.plot(range(len(loss_list)), loss_list)\n",
        "plt.xlim=(0, len(loss_list))\n",
        "plt.ylim=(0, max(loss_list))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "PqM4xIt17mWw",
        "outputId": "ae55822a-9974-4d30-ebdf-46f0f12bdc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順7\n",
        "\n",
        "学習後のモデルを用いて、テストデータに対するROC AUCを評価してください。"
      ],
      "metadata": {
        "id": "uCGv8CCKLg-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータのcsvファイルをダウンロード\n",
        "url='https://drive.google.com/uc?export=download&id=1VSS6Juhj6NJrDhW7aOic8oz8v4yAGP0v'\n",
        "gdown.download(url, 'kadai1_data_test.csv', quiet=False)\n",
        "print('\\n')\n",
        "\n",
        "# csvファイルをデータフレームとして読み込む\n",
        "df_test = pd.read_csv('kadai1_data_test.csv')\n",
        "\n",
        "# データフレームをX_testとy_test_trueに分けて、numpyアレイに変換\n",
        "X_test = df_test.iloc[:, :-1]\n",
        "y_test_true = df_test.iloc[:, -1]\n",
        "X_test = X_test.to_numpy()\n",
        "y_test_true = y_test_true.to_numpy()\n",
        "\n",
        "# 学習後のモデルを用いてテストデータの予測値を計算\n",
        "y_test_pred = np.zeros(y_test_true.shape[0])\n",
        "for i in range(y_test_true.shape[0]):\n",
        "    vars = forward_prop(X_test[i, :], params)\n",
        "    y_test_pred[i] = vars['y_pred']\n",
        "\n",
        "# テストデータに対するROC AUC\n",
        "auc_test = roc_auc_score(y_true=y_test_true, y_score=y_test_pred)\n",
        "print('ROC AUC on test data: {}'.format(auc_test))\n",
        "\n",
        "# デバッグ用\n",
        "# y_predはinf, nanなどの異常値になっていないか。\n",
        "# y_predが全てのデータに対して同じ値になっているなどの場合も異常なので、\n",
        "# バグがないか振り返って確認しよう。\n",
        "print('y_test_true:\\n{}'.format(y_test_true))\n",
        "print('y_test_pred:\\n{}'.format(y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IVi9BoP5DQ0",
        "outputId": "8e128259-8f31-413d-e70d-1c4a2df912ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1VSS6Juhj6NJrDhW7aOic8oz8v4yAGP0v\n",
            "To: /content/kadai1_data_test.csv\n",
            "100%|██████████| 834/834 [00:00<00:00, 2.15MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ROC AUC on test data: 1.0\n",
            "y_test_true:\n",
            "[1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1]\n",
            "y_test_pred:\n",
            "[0.99817242 0.99826675 0.00335799 0.997999   0.00226909 0.00220815\n",
            " 0.00223541 0.00231925 0.00309442 0.00327559 0.00241709 0.9981112\n",
            " 0.00245398 0.9977289  0.00245861 0.99774066 0.99829649 0.99778581\n",
            " 0.99572062 0.99724752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順8\n",
        "\n",
        "以上の結果を考察してください。学習前と比較して学習後の損失関数の値は低下しているでしょうか。学習は収束していると言えるでしょうか。学習データに対する予測はうまくいっているでしょうか。テストデータに対する予測はうまくいっているでしょうか。"
      ],
      "metadata": {
        "id": "qIywFijdVCz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【解答欄】\n",
        "# ここに考察を書いてください。\n",
        "# 学習前と学習後を比較して、損失関数の値は0.717から0.002に低下した。\n",
        "# 学習曲線を見ると、エポック400あたりから損失関数の値がほとんど変化しなくなっている。\n",
        "# このことから学習は収束していると言える。\n",
        "# 学習データに対する予測ではROC AUCが1.0となっており、うまくフィッティングできていると考えられる。\n",
        "# テストデータに対する予測でもROC AUCが1.0となっているため、概ねうまく予測できていると考えられる。"
      ],
      "metadata": {
        "id": "m6YBENLcxB7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題2\n",
        "\n",
        "自動微分をPythonで1から書いてみましょう。primitive演算として足し算、掛け算、累乗を考えます。自動微分を用いることにより、様々な関数の微分を簡単に計算できることを確認しましょう。以下の手順に沿って進めてください。"
      ],
      "metadata": {
        "id": "Gbd3uvOTE4x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順1\n",
        "\n",
        "まず、練習のために、計算グラフのノードを表すクラス`ValueNodePractice1`を書いてください。ノード同士のprimitive演算を演算子のオーバーロードによって定義し、計算結果のノードが自動的に作られるようにしてください。\n",
        "\n",
        "※演算子のオーバーロードについては、「プログラミングⅡ」第19,20回を適宜復習してください。"
      ],
      "metadata": {
        "id": "RcKmrkdkER5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算グラフのノードを表すクラス\n",
        "class ValueNodePractice1:\n",
        "    # コンストラクタ\n",
        "    def __init__(self, data):\n",
        "        self.data = data # ノードがもつ変数の値\n",
        "        self.prev = [] # このノードを計算する際に使用したノードのリスト\n",
        "\n",
        "    # primitive演算: 足し算\n",
        "    # self + other\n",
        "    def __add__(self, other):\n",
        "        # otherが計算グラフのノードならそのまま用いる\n",
        "        if isinstance(other, ValueNodePractice1):\n",
        "            other = other\n",
        "        # ただのスカラーならノード化してから用いる\n",
        "        else:\n",
        "            other = ValueNodePractice1(other)\n",
        "        # 計算結果のノードoutを新しく作る\n",
        "        out = ValueNodePractice1(self.data + other.data)\n",
        "        # outを計算する際にself, otherを使用したので記録しておく\n",
        "        out.prev = [self, other]\n",
        "        # 計算結果としてノードoutを返す\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # self * other\n",
        "    def __mul__(self, other):\n",
        "        # otherが計算グラフのノードならそのまま用いる\n",
        "        if isinstance(other, ValueNodePractice1):\n",
        "            other = other\n",
        "        # ただのスカラーならノード化してから用いる\n",
        "        else:\n",
        "            other = ValueNodePractice1(other)\n",
        "        # 計算結果のノードoutを新しく作る\n",
        "        out = ValueNodePractice1(self.data * other.data)\n",
        "        # outを計算する際にself, otherを使用したので記録しておく\n",
        "        out.prev = [self, other]\n",
        "        # 計算結果としてノードoutを返す\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # other * self\n",
        "    # self * otherと同じ処理を行う\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    # primitive演算: 累乗\n",
        "    # self ** power\n",
        "    # 今回は簡単のためpowerはノード化しない\n",
        "    def __pow__(self, power):\n",
        "        # 計算結果のノードoutを新しく作る\n",
        "        out = ValueNodePractice1(self.data ** power)\n",
        "        # outを計算する際にselfを使用したので記録しておく\n",
        "        out.prev = [self]\n",
        "        # 計算結果としてノードoutを返す\n",
        "        return out\n",
        "\n",
        "    # 計算グラフの確認用\n",
        "    # ノードの値と計算に使用したノードを再帰的に表示\n",
        "    def explain_me(self):\n",
        "        print('ノードの値: {}'.format(self.data))\n",
        "        if len(self.prev) != 0:\n",
        "            print('>> このノードの計算に使用したノード :')\n",
        "            for v in self.prev:\n",
        "                v.explain_me()\n",
        "\n",
        "\n",
        "# 動作確認用1\n",
        "print('例1. x3 = x1 + x2 の計算グラフ')\n",
        "# コンストラクタでノードx1, x2を作る\n",
        "x1 = ValueNodePractice1(5.0)\n",
        "x2 = ValueNodePractice1(7.0)\n",
        "# 計算結果のノードx3が自動的に作られる\n",
        "x3 = x1 + x2\n",
        "# 計算グラフの確認\n",
        "x3.explain_me()\n",
        "print('\\n')\n",
        "\n",
        "# 動作確認用2\n",
        "print('例2. x5 = x4 * x3の計算グラフ')\n",
        "# コンストラクタでノードx4を作る\n",
        "x4 = ValueNodePractice1(2.0)\n",
        "# 計算結果のノードx5が自動的に作られる\n",
        "x5 = x4 * x3\n",
        "# 計算グラフの確認\n",
        "x5.explain_me()\n",
        "print('\\n')\n",
        "\n",
        "# 動作確認用3\n",
        "print('例3. x6 = x5 ** 2の計算グラフ')\n",
        "# 計算結果のノードx6が自動的に作られる\n",
        "x6 = x5 ** 2\n",
        "# 計算グラフの確認\n",
        "x6.explain_me()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO2uZlypsBCn",
        "outputId": "37a5d263-c94a-4473-d7af-54cff4135208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "例1. x3 = x1 + x2 の計算グラフ\n",
            "ノードの値: 12.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 5.0\n",
            "ノードの値: 7.0\n",
            "\n",
            "\n",
            "例2. x5 = x4 * x3の計算グラフ\n",
            "ノードの値: 24.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 2.0\n",
            "ノードの値: 12.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 5.0\n",
            "ノードの値: 7.0\n",
            "\n",
            "\n",
            "例3. x6 = x5 ** 2の計算グラフ\n",
            "ノードの値: 576.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 24.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 2.0\n",
            "ノードの値: 12.0\n",
            ">> このノードの計算に使用したノード :\n",
            "ノードの値: 5.0\n",
            "ノードの値: 7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順2\n",
        "\n",
        "手順1で作成した`ValueNodePractice1`に自動微分の機能を追加したクラス`ValueNodePractice2`を作ってください。"
      ],
      "metadata": {
        "id": "4WSzE3CNMUEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算グラフのノードを表すクラス\n",
        "# 自動微分対応版\n",
        "class ValueNodePractice2:\n",
        "    # コンストラクタ\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.prev = []\n",
        "        # ノードの変数に関する微分の値 d_f / d_data\n",
        "        self.grad = 0.0 # 初期値は0.0に設定\n",
        "        # エッジを逆向きにたどる際の演算を表す関数\n",
        "        self.backward = lambda: None # 初期値はラムダ式で適当な関数を設定\n",
        "\n",
        "    # primitive演算: 足し算\n",
        "    # self + other\n",
        "    def __add__(self, other):\n",
        "        # 最初はValueNodePractice1と同じ\n",
        "        if isinstance(other, ValueNodePractice2):\n",
        "            other = other\n",
        "        else:\n",
        "            other = ValueNodePractice2(other)\n",
        "        out = ValueNodePractice2(self.data + other.data)\n",
        "        out.prev = [self, other]\n",
        "        # outからself, otherにむかってエッジを逆向きにたどる際の演算\n",
        "        # out = self + other なので d_out / d_self = 1\n",
        "        # out = self + other なので d_out/ d_other = 1\n",
        "        def backward():\n",
        "            self.grad += out.grad * 1 # d_out / d_self を乗算してself.gradに渡す\n",
        "            other.grad += out.grad * 1 # d_out / d_other を乗算してother.gradに渡す\n",
        "        # 上で定義した関数をout.backwardとして設定\n",
        "        out.backward = backward\n",
        "        # 計算結果としてノードoutを返す\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # self * other\n",
        "    def __mul__(self, other):\n",
        "        # 最初はValueNodePractice1と同じ\n",
        "        if isinstance(other, ValueNodePractice2):\n",
        "            other = other\n",
        "        else:\n",
        "            other = ValueNodePractice2(other)\n",
        "        out = ValueNodePractice2(self.data * other.data)\n",
        "        out.prev = [self, other]\n",
        "        # outからself, otherにむかってエッジを逆向きにたどる際の演算\n",
        "        # out = self * other なので d_out / d_self = other.data\n",
        "        # out = self * other なので d_out/ d_other = self.data\n",
        "        def backward():\n",
        "            self.grad += out.grad * other.data # d_out / d_self を乗算してself.gradに渡す\n",
        "            other.grad += out.grad * self.data # d_out / d_other を乗算してother.gradに渡す\n",
        "        # 上で定義した関数をout.backwardとして設定\n",
        "        out.backward = backward\n",
        "        # 計算結果としてノードoutを返す\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # other * self\n",
        "    # self * otherと同じ処理を行う\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    # primitive演算: 累乗\n",
        "    # self ** power\n",
        "    # 今回は簡単のためpowerはノード化しない\n",
        "    def __pow__(self, power):\n",
        "        # 最初はValueNodePractice1と同じ\n",
        "        out = ValueNodePractice2(self.data ** power)\n",
        "        out.prev = [self]\n",
        "        # outからselfにむかってエッジを逆向きにたどる際の演算\n",
        "        # out = self ** power なので d_out / d_self = power * self.data ** (power-1)\n",
        "        def backward():\n",
        "            self.grad += out.grad * power * self.data ** (power-1) # d_out / d_self を乗算してself.gradに渡す\n",
        "        # 上で定義した関数をout.backwardとして設定\n",
        "        out.backward = backward\n",
        "        # 計算結果としてノードを返す\n",
        "        return out\n",
        "\n",
        "    # このノードからエッジを逆向きにたどり全ノードのbackward()を実行する関数\n",
        "    # backward_all()を実行すると、\n",
        "    #「このノードの変数を各ノードの変数で微分した値」が計算され、\n",
        "    # その結果が各ノードの.gradに入る。\n",
        "    #\n",
        "    # 今回はこちらでコード例を用意済み。\n",
        "    # ざっくりした説明:\n",
        "    # 各ノードのprevを再帰的に調べて順番にbackward()を実行している。\n",
        "    def backward_all(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v.prev:\n",
        "                    build(child)\n",
        "                topo.append(v)\n",
        "        build(self)\n",
        "        self.grad = 1.0\n",
        "        for node in reversed(topo):\n",
        "            node.backward()\n",
        "\n",
        "\n",
        "# 動作確認用\n",
        "# 「深層学習入門」第4回の練習問題で扱った\n",
        "# y = (x1 + 2 * x2) ** 2の自動微分\n",
        "\n",
        "# 計算グラフの構築\n",
        "x1 = ValueNodePractice2(3.0)\n",
        "x2 = ValueNodePractice2(5.0)\n",
        "y = (x1 + 2 * x2) ** 2\n",
        "# 各変数に関するyの微分を計算\n",
        "y.backward_all()\n",
        "# yのx1に関する微分\n",
        "print(\"dy/dx1 = {}\".format(x1.grad)) # 26\n",
        "# yのx2に関する微分\n",
        "print(\"dy/dx2 = {}\".format(x2.grad)) # 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6m55in0BaEb",
        "outputId": "3000c7e7-bc1f-4961-fe64-5d68d8ef90bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx1 = 26.0\n",
            "dy/dx2 = 52.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順3\n",
        "\n",
        "手順2で作成した`ValueNodePractice2`を用いて、「深層学習入門」第4回の講義内課題で扱った$y = (3 x_1 + x_2)^2$の自動微分を計算してください。$x_1 = 3, x_2 = 5$とします。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1lf05LGpQf_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算グラフの構築\n",
        "x1 = ValueNodePractice2(3.0)\n",
        "x2 = ValueNodePractice2(5.0)\n",
        "y = (3 * x1 + x2) ** 2\n",
        "# yの各変数に関する微分を計算\n",
        "y.backward_all()\n",
        "# yのx1に関する微分\n",
        "print(\"dy/dx1 = {}\".format(x1.grad)) # 84\n",
        "# yのx2に関する微分\n",
        "print(\"dy/dx2 = {}\".format(x2.grad)) # 28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G3u_j8gIthN",
        "outputId": "ec60bf77-35e5-4c2a-ee9b-c5c6c7747195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx1 = 84.0\n",
            "dy/dx2 = 28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順4\n",
        "\n",
        "`ValueNodePractice2`で計算可能な微分の問題を自分で1つ作成して、手計算と自動微分で同じ答えが出ることを確認してください。primitive演算として足し算、掛け算、累乗しか使えないので注意。"
      ],
      "metadata": {
        "id": "bC9Pz8AMR7qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【解答欄】\n",
        "# コメントに自分で作成した微分の問題を書いてください。\n",
        "# y = ????\n",
        "# x1 = ????\n",
        "# ...\n",
        "\n",
        "# 手計算で解く場合の計算式と答えをコメントに書いてください。\n",
        "# dy / dx1 = ...\n",
        "\n",
        "# 自動微分で解く場合のコードを書いて実行し、答えを表示してください。\n",
        "ここに書く"
      ],
      "metadata": {
        "id": "yjeh4Wp_Sja6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "手順5\n",
        "\n",
        "`ValueNodePractice2`を元にして、いくつかのprimitive演算を追加したクラス`ValueNodePractice3`を作ってください。このクラスの自動微分の機能を使って、講義資料の勾配降下法の問題を計算して答えを表示してください。"
      ],
      "metadata": {
        "id": "fgJvUngbnBPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算グラフのノードを表すクラス\n",
        "class ValueNodePractice3:\n",
        "    # コンストラクタ\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.prev = []\n",
        "        self.grad = 0.0\n",
        "        self.backward = lambda: None\n",
        "\n",
        "    # primitive演算: 足し算\n",
        "    # self + other\n",
        "    def __add__(self, other):\n",
        "        if isinstance(other, ValueNodePractice3):\n",
        "            other = other\n",
        "        else:\n",
        "            other = ValueNodePractice3(other)\n",
        "        out = ValueNodePractice3(self.data + other.data)\n",
        "        out.prev = [self, other]\n",
        "        def backward():\n",
        "            self.grad += out.grad * 1\n",
        "            other.grad += out.grad * 1\n",
        "        out.backward = backward\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # self * other\n",
        "    def __mul__(self, other):\n",
        "        if isinstance(other, ValueNodePractice3):\n",
        "            other = other\n",
        "        else:\n",
        "            other = ValueNodePractice3(other)\n",
        "        out = ValueNodePractice3(self.data * other.data)\n",
        "        out.prev = [self, other]\n",
        "        def backward():\n",
        "            self.grad += out.grad * other.data\n",
        "            other.grad += out.grad * self.data\n",
        "        out.backward = backward\n",
        "        return out\n",
        "\n",
        "    # primitive演算: 掛け算\n",
        "    # other * self\n",
        "    # self * otherと同じ処理を行う\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    # primitive演算: 累乗\n",
        "    # self ** power\n",
        "    # 今回は簡単のためpowerはノード化しない\n",
        "    def __pow__(self, power):\n",
        "        out = ValueNodePractice3(self.data ** power)\n",
        "        out.prev = [self]\n",
        "        def backward():\n",
        "            self.grad += out.grad * power * self.data ** (power-1)\n",
        "        out.backward = backward\n",
        "        return out\n",
        "\n",
        "    # このノードからエッジを逆向きにたどり全ノードのbackward()を実行する関数\n",
        "    def backward_all(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v.prev:\n",
        "                    build(child)\n",
        "                topo.append(v)\n",
        "        build(self)\n",
        "        self.grad = 1.0\n",
        "        for node in reversed(topo):\n",
        "            node.backward()\n",
        "\n",
        "    # primitive演算: 足し算\n",
        "    # other + self\n",
        "    def __radd__(self, other):\n",
        "        return self + other\n",
        "    # primitive演算: マイナス\n",
        "    # -self\n",
        "    def __neg__(self):\n",
        "        return self * -1\n",
        "    # primitive演算: 引き算\n",
        "    # self - other\n",
        "    def __sub__(self, other):\n",
        "        return self + (-other)\n",
        "    # primitive演算: 引き算\n",
        "    # other - self\n",
        "    def __rsub__(self, other):\n",
        "        return other + (-self)\n",
        "\n",
        "\n",
        "# 講義資料の問題を解く\n",
        "# 目的関数のw1, w2に関する微分を計算したいので、\n",
        "# w1, w2をValueNodePractice3のインスタンスとして定義。\n",
        "w1 = ValueNodePractice3(1.0)\n",
        "w2 = ValueNodePractice3(1.0)\n",
        "\n",
        "print('1回目の更新後のw1, w2の値')\n",
        "# 目的関数の定義、計算グラフの構築\n",
        "f = (w1 + 4*w2 -7) ** 2 + (w1 - w2 + 3) ** 2\n",
        "# 各変数に関するfの微分を計算\n",
        "f.backward_all()\n",
        "# 勾配降下法\n",
        "w1.data -= 0.1 * w1.grad\n",
        "w2.data -= 0.1 * w2.grad\n",
        "# 更新後のw1, w2の値\n",
        "print(\"w1 = {}\".format(w1.data)) # 0.8\n",
        "print(\"w2 = {}\".format(w2.data)) # 3.2\n",
        "# 勾配のリセット\n",
        "w1.grad = 0.0\n",
        "w2.grad = 0.0\n",
        "\n",
        "print('2回目の更新後のw1, w2の値')\n",
        "# 目的関数の定義、計算グラフの構築\n",
        "f = (w1 + 4*w2 -7) ** 2 + (w1 - w2 + 3) ** 2\n",
        "# fの各変数に関する微分を計算\n",
        "f.backward_all()\n",
        "# 勾配降下法\n",
        "w1.data -= 0.1 * w1.grad\n",
        "w2.data -= 0.1 * w2.grad\n",
        "# 更新後のw1, w2の値\n",
        "print(\"w1 = {}\".format(w1.data)) # -0.64\n",
        "print(\"w2 = {}\".format(w2.data)) # -1.96"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inWR9BlakP84",
        "outputId": "17b0e9e2-6f82-4e70-e8f5-e698ce8a8787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1回目の更新後のw1, w2の値\n",
            "w1 = 0.8\n",
            "w2 = 3.2\n",
            "2回目の更新後のw1, w2の値\n",
            "w1 = -0.6400000000000003\n",
            "w2 = -1.9600000000000009\n"
          ]
        }
      ]
    }
  ]
}